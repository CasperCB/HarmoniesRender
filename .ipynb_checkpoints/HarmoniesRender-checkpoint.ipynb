{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93cd1d13-2b38-42d7-b183-2cf8f3348d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d89262-9d21-4147-84de-09bc588d9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## image processing and token detection functions ##\n",
    "\n",
    "def findBoard(image, threshold):\n",
    "    \"\"\"\n",
    "    Finds location of game baord given input image and crops to the game board.\n",
    "\n",
    "    Args:\n",
    "        image: BGR image (as read by cv2.imread)\n",
    "        threshhold: low threshold value for Canny edge detection\n",
    "        \n",
    "    Returns:\n",
    "        board_region: BGR image cropped to the game board\n",
    "    \"\"\"\n",
    "    \n",
    "    # convert to gray\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # detect edges\n",
    "    edges = cv2.Canny(gray, threshold, 150)\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # crop to game board\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "    board_region = image[y:y+h, x:x+w] \n",
    "\n",
    "    return board_region\n",
    "\n",
    "\n",
    "def extractHexVectors(board, hex_centers, color_ranges):\n",
    "    \"\"\"\n",
    "    Extracts color counts for each hex on the game board and ouptus them as a vector.\n",
    "\n",
    "    Args:\n",
    "        board: BGR image cropped to the board \n",
    "        hex_centers: List of (x, y) tuples representing the coordinates of hex centers\n",
    "        color_ranges: Dict of token_type -> (lower_bgr, upper_bgr)\n",
    "\n",
    "    Returns:\n",
    "        List of dicts: [{'coord': [x, y], 'vector': {'red': ..., 'blue': ..., ...}}, ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    vectors = []\n",
    "    \n",
    "    # convert to rgb\n",
    "    board = cv2.cvtColor(board, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # loop over all hexagons on the board\n",
    "    for (hex_x, hex_y) in hex_centers:\n",
    "        roi = board[hex_y - 25 : hex_y + 25, hex_x - 10 : hex_x + 10] # region of interest\n",
    "        vector = {}\n",
    "\n",
    "        # loop over all possible token types\n",
    "        for token_type, (lower, upper) in color_ranges.items():\n",
    "            lower_np = np.array(lower, dtype=np.uint8)\n",
    "            upper_np = np.array(upper, dtype=np.uint8)\n",
    "            mask = cv2.inRange(roi, lower_np, upper_np)\n",
    "            pixel_count = cv2.countNonZero(mask) # count # of pixels within token's color range\n",
    "\n",
    "            # Adjust spirit token count by subtracting board pixels, since color ranges are similar\n",
    "            if token_type == \"spirit\":\n",
    "                board_mask = cv2.inRange(roi, np.array(color_ranges[\"board\"][0]), np.array(color_ranges[\"board\"][1]))\n",
    "                pixel_count = max(0, pixel_count - cv2.countNonZero(board_mask))\n",
    "\n",
    "            vector[token_type] = int(pixel_count)\n",
    "\n",
    "        vectors.append({\n",
    "            \"coord\": [hex_x, hex_y],\n",
    "            \"vector\": vector\n",
    "        })\n",
    "\n",
    "    return vectors\n",
    "\n",
    "\n",
    "def classify_vector(input_vector, token_avgs):\n",
    "    \"\"\"\n",
    "    Given a pixel count vector, return the top matching label from a vector database of average values.\n",
    "    \n",
    "    Args:\n",
    "        input_vector (dict): e.g., {'red': 0, 'blue': 172, ..., 'animal': 133}\n",
    "        token_vectors (pd.DataFrame) - database of tokens vectors, averaged from labeled data\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: [(label, similarity_score), ...]\n",
    "    \"\"\"\n",
    "    \n",
    "    # ensure vectors are in the same order\n",
    "    token_order = token_avgs.index.tolist()\n",
    "    input_array = np.array([[input_vector.get(token, 0) for token in token_order]])  # shape (1, n_tokens)\n",
    "\n",
    "    # transpose for cosine similarity: now shape (n_labels, n_tokens)\n",
    "    label_vectors = token_avgs.T.values\n",
    "    label_names = token_avgs.columns.tolist()\n",
    "\n",
    "    # cosine similarity\n",
    "    similarities = cosine_similarity(input_array, label_vectors)[0]\n",
    "    best_index = similarities.argmax()\n",
    "\n",
    "    return label_names[best_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca11f5a-2be8-45a4-a458-78f1746ab6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image and other necessary data\n",
    "image = cv2.imread('C:/Users/lacto/Documents/GitHub/HarmoniesRender/training_boards/cropped_Board6.jpg')\n",
    "\n",
    "# get reference coordinates for hexagon centers\n",
    "f = open('hex_positions.json')\n",
    "hex_centers = json.load(f)\n",
    "\n",
    "# load token color ranges\n",
    "f = open('token_color_ranges.json')\n",
    "color_ranges = json.load(f)\n",
    "\n",
    "# load token vectors\n",
    "token_avgs = pd.read_csv('average_token_vectors.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4cf73d8-f33e-4ed7-9c8d-6ef7cec7c384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN ##\n",
    "\n",
    "# crop image to board state\n",
    "board = findBoard(image, threshhold = 50)\n",
    "\n",
    "# count number of pixels in each token's color range for each board hex\n",
    "hex_vectors = extractHexVectors(board, hex_centers, color_ranges)\n",
    "\n",
    "# use pixel counts to detect tokens, cubes, and the stack order\n",
    "labels = []\n",
    "for hex_entry in vectors: # for each board hex\n",
    "    input_vector = hex_entry[\"vector\"] # get vector of color counts\n",
    "    label = classify_vector(input_vector, token_avgs) # use cosine similarity to classify vector\n",
    "    labels.append({\n",
    "        \"coord\": hex_entry[\"coord\"],\n",
    "        \"label\": label\n",
    "    }) \n",
    "\n",
    "# infer spirit and animal placement\n",
    "\n",
    "# infer terrain and habitat features\n",
    "# - Spirt Card\n",
    "# - Animal Cards\n",
    "# - Tokens (Green, Yellow, Blue, Gray, Red, Brown)\n",
    "# - Token density\n",
    "\n",
    "# infer arrangement of features \n",
    "\n",
    "# combine inferences with stylistic preferences\n",
    "\n",
    "# create image\n",
    "\n",
    "# save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3378e65-79bb-42bc-bca8-53d114062251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4dee0a-bf91-4b7b-b73a-2cfd755fb821",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
